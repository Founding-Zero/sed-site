<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Language Control Diffusion: Efficiently Generalizing through Space, Time, and Tasks</title>



  <!-- custom fonts -->
  <link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
  <link href="https://fonts.cdnfonts.com/css/proxima-nova-2" rel="stylesheet">
  <!-- end custom fonts -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="ico" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://eddie.win">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <!-- <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://hypernerf.github.io">
              HyperNeRF
            </a>
            <a class="navbar-item" href="https://nerfies.github.io">
              Nerfies
            </a>
            <a class="navbar-item" href="https://latentfusion.github.io">
              LatentFusion
            </a>
            <a class="navbar-item" href="https://photoshape.github.io">
              PhotoShape
            </a>
          </div>
        </div> -->
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Language Control Diffusion: Efficiently Generalizing through Space,
              Time, and Tasks</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://eddie.win">Eddie Zhang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://yujielu10.github.io/">Yujie Lu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://sites.cs.ucsb.edu/~william/">William Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://amyzhang.github.io/">Amy Zhang</a><sup>2</sup>
              </span>

            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UC Santa Barbara,</span>
              <span class="author-block"><sup>2</sup>UT Austin</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2210.15629.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2210.15629" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data (coming soon)</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <!-- <source src="./static/videos/teaser.mp4" type="video/mp4"> -->
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">lcd</span> scales diffusion models for long horizon and language conditioned planning.
        </h2>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <!-- <div id="results-carousel" class="carousel results-carousel"
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div> -->
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Training generalist agents is difficult across several axes, requiring us to deal with high dimensional
              inputs (space), long horizons (time), and multiple and new tasks. Recent advances with architectures have
              allowed for improved scaling along one or two of these dimensions, but are still prohibitive
              computationally. In this paper, we propose to address all three axes by leveraging Language to Control
              Diffusion models as a hierarchical planner conditioned on language <span class="dnerf">lcd</span>.
            </p>
            <p>
              We effectively and efficiently scale diffusion models for planning in extended temporal, state, and task
              dimensions to tackle long
              horizon control problems conditioned on natural language instructions. We compare LCD with other
              state-of-the-art models on the CALVIN language robotics benchmark and find that LCD outperforms other
              SOTA methods in multi task success rates while dramatically improving computational efficiency with a
              single task success rate (SR) of <strong>87%</strong> against the previous best of <strong>82.7%</strong>.
            </p>
            <p>
              We show that LCD can successfully
              leverage the unique strength of diffusion models to produce coherent long range plans while addressing
              their weakness at generating low-level details and contro
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>


  <!--/ Animation. -->


  <!-- Concurrent Work. -->
  <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              There's a lot of excellent work that was introduced around the same time as ours.
            </p>
            <p>
              <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an
              idea similar to our windowed position encoding for coarse-to-fine optimization.
            </p>
            <p>
              <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
              both use deformation fields to model non-rigid scenes.
            </p>
            <p>
              Some works model videos with a NeRF by directly modulating the density, such as <a
                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                href="https://neural-3d-video.github.io/">DyNeRF</a>
            </p>
            <p>
              There are probably many more by the time you are reading this. Check out <a
                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a
                href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
            </p>
          </div>
        </div>
      </div> -->
  <!--/ Concurrent Work. -->

  </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhang2022lad,
  author    = {Zhang, Edwin and Lu, Yujie and Wang, William and Zhang, Amy},
  title     = {Language Control Diffusion: Efficiently Generalizing through Space, Time, and Tasks},
  journal   = {arXiv},
  year      = {2023},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">

      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center
            ">
              Website templated borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies.</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>